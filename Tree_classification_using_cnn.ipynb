{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "cats-dogs-classification-using-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BLOSSOM1994/Tree_maskRcnn/blob/master/Tree_classification_using_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REZb5xeDCvE3",
        "colab_type": "text"
      },
      "source": [
        "The Idea is to apply CNN to Cats&Dogs Image Classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02M8n8QSCvE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from zipfile import ZipFile "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDrmWMJdCvFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries for Deep Learning\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCmXa2bjEAjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "10e2e6d4-9e22-4c99-cc8b-02064558800c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "chAn0DlOCvFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into train, validate and test data folders\n",
        "datadir='/content/drive/My Drive/Colab Notebooks'\n",
        "train_dir  = datadir+'/CNN_test/train'\n",
        "test_dir   = datadir+'/CNN_test/test'\n",
        "\n",
        "\n",
        "train_dir_tree = train_dir + '/tree'\n",
        "train_dir_any = train_dir + '/any'\n",
        "test_dir_tree = test_dir + '/tree'\n",
        "test_dir_any = test_dir + '/any'\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWLOvgmrCvFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "df2d1afb-15e1-4018-e9b9-96f68d6546f0"
      },
      "source": [
        "print('number of tree training images - ',len(os.listdir(train_dir_tree)))\n",
        "print('number of any training images - ',len(os.listdir(train_dir_any)))\n",
        "print('number of tree testing images - ',len(os.listdir(test_dir_tree)))\n",
        "print('number of any testing images - ',len(os.listdir(test_dir_any)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of tree training images -  162\n",
            "number of any training images -  77\n",
            "number of tree testing images -  117\n",
            "number of any testing images -  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCRkjWvYCvF7",
        "colab_type": "text"
      },
      "source": [
        "Now we need to convert the RGB images into array of numbers. The requirement can be satisfied by ImageDataGenerator() https://keras.io/preprocessing/image/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux0EgaaCCvF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator = ImageDataGenerator(rescale = 1.0/255.0, zoom_range = 0.2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Sd6bi_CvGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3ad39378-e1bb-45dc-f37a-0003bbb21926"
      },
      "source": [
        "batch_size = 32\n",
        "training_data = data_generator.flow_from_directory(directory = train_dir,\n",
        "                                                   target_size = (64, 64),\n",
        "                                                   batch_size = batch_size,\n",
        "                                                   class_mode = 'binary')\n",
        "testing_data = data_generator.flow_from_directory(directory = test_dir,\n",
        "                                                  target_size = (64, 64),\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode = 'binary')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 239 images belonging to 2 classes.\n",
            "Found 173 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnTvaiHECvGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preparing the layers in the Convolutional Deep Neural Network\n",
        "model = Sequential()\n",
        "\n",
        "#Convolutional Layer 1 w/ Pooling\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = training_data.image_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.3))\n",
        "\n",
        "#Convolutional Layer 2 w/ Pooling\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "\n",
        "#Convolutional Layer 3 w/ Pooling\n",
        "model.add(Conv2D(filters = 126, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.15))\n",
        "\n",
        "#Fully Connected Layer w/ Dropout\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.15))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.1))\n",
        "\n",
        "#Output Layer\n",
        "model.add(Dense(units = len(set(training_data.classes)), activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoqW4_ZpCvGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "7d8ea2d2-3837-4e86-85c9-08d75023b49d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 12, 12, 126)       72702     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 6, 6, 126)         0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 6, 6, 126)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 4536)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                145184    \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 239,520\n",
            "Trainable params: 239,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P46XoYDpCvGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "c9678861-ba01-43fe-fa53-5bb5bd8832f5"
      },
      "source": [
        "fitted_model = model.fit_generator(training_data,\n",
        "                        steps_per_epoch = int(239/batch_size),\n",
        "                        epochs = 25,\n",
        "                        validation_data = testing_data,\n",
        "                        validation_steps = int(173/batch_size))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6483 - accuracy: 0.6607 - val_loss: 0.6487 - val_accuracy: 0.6750\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.6191 - accuracy: 0.6908 - val_loss: 0.6313 - val_accuracy: 0.6812\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 22s 3s/step - loss: 0.6051 - accuracy: 0.6715 - val_loss: 0.6386 - val_accuracy: 0.6750\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.5804 - accuracy: 0.6908 - val_loss: 0.5896 - val_accuracy: 0.6687\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.5380 - accuracy: 0.6715 - val_loss: 0.5501 - val_accuracy: 0.7688\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 20s 3s/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7812\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.4254 - accuracy: 0.7778 - val_loss: 0.4714 - val_accuracy: 0.7437\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.3854 - accuracy: 0.8068 - val_loss: 0.5164 - val_accuracy: 0.7188\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.3988 - accuracy: 0.7857 - val_loss: 0.5411 - val_accuracy: 0.6750\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.4167 - accuracy: 0.8080 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.3752 - accuracy: 0.8164 - val_loss: 0.4544 - val_accuracy: 0.7937\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 22s 3s/step - loss: 0.3798 - accuracy: 0.8261 - val_loss: 0.4602 - val_accuracy: 0.7625\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 22s 3s/step - loss: 0.3597 - accuracy: 0.8304 - val_loss: 0.3770 - val_accuracy: 0.8500\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.2838 - accuracy: 0.8599 - val_loss: 0.4068 - val_accuracy: 0.8562\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.3007 - accuracy: 0.8744 - val_loss: 0.3844 - val_accuracy: 0.8625\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.2674 - accuracy: 0.8792 - val_loss: 0.3783 - val_accuracy: 0.8125\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 20s 3s/step - loss: 0.2425 - accuracy: 0.9082 - val_loss: 0.4948 - val_accuracy: 0.8250\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.3099 - accuracy: 0.8647 - val_loss: 0.3639 - val_accuracy: 0.8438\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.2540 - accuracy: 0.9082 - val_loss: 0.3501 - val_accuracy: 0.8750\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.2859 - accuracy: 0.8705 - val_loss: 0.3413 - val_accuracy: 0.8875\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 24s 3s/step - loss: 0.2118 - accuracy: 0.9275 - val_loss: 0.3284 - val_accuracy: 0.8750\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.1778 - accuracy: 0.9469 - val_loss: 0.3355 - val_accuracy: 0.8938\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.2181 - accuracy: 0.9082 - val_loss: 0.3370 - val_accuracy: 0.8750\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 21s 3s/step - loss: 0.1703 - accuracy: 0.9517 - val_loss: 0.3003 - val_accuracy: 0.9000\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 22s 3s/step - loss: 0.1652 - accuracy: 0.9469 - val_loss: 0.3568 - val_accuracy: 0.8687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG3pgwNDCvGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "25fb4c29-ae4a-47bb-c4ee-7cc085630d07"
      },
      "source": [
        "# plotting accuracy and validation accuracy\n",
        "accuracy = fitted_model.history['accuracy']\n",
        "plt.plot(range(len(accuracy)), accuracy, 'bo', label = 'accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5704d4c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vppZMvKCvG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing the model\n",
        "def testing_image(image_directory):\n",
        "    test_image = image.load_img(image_directory, target_size = (64, 64))\n",
        "    test_image = image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "    result = model.predict(x = test_image)\n",
        "    print(result)\n",
        "    if result[0][0]  == 1:\n",
        "        prediction = 'Any'\n",
        "    else:\n",
        "        prediction = 'Tree'\n",
        "    return prediction"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g96f2vOICvHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f5b726b-3b93-49a6-a027-3c18983f46cd"
      },
      "source": [
        "print(testing_image(test_dir + '/any/donmy.JPG'))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n",
            "Tree\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOui7hKQVixU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eaf59a78-63c5-447f-f10e-954ab69da399"
      },
      "source": [
        "print(testing_image(test_dir + '/any/glio.JPG'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]]\n",
            "Any\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP9Zn01YVxoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "98b3ec69-8547-4e4e-a4b3-367ff5571f0b"
      },
      "source": [
        "print(testing_image(test_dir + '/any/IMG_4753 - Copy.JPG'))\n",
        "#123.JPG\n",
        "#IMG_4796.JPG\n",
        "#5567.JPG\n",
        "#IMG_4753 - Copy.JPG\n",
        "#jhkuyi.JPG"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]]\n",
            "Any\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}