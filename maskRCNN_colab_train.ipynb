{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"maskRCNN_colab_train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9LJlvDUIM40S"},"source":["## Load Mask RCNN into Google Colab"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qQ3TkVnPUTXW","colab":{}},"source":["!git clone https://github.com/matterport/Mask_RCNN"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"p_ZklvupM_ST"},"source":["## Set up the GPU Environment\n","In Colabs go to:  \n","Edit > Notebook Settings  \n","Set the hardware accelerator to 'GPU' and reload the notebook. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QDyJKAJZmq8M","colab":{}},"source":["#RUN GPU\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"L9TR3tlENFbR"},"source":["## Move into the Mask RCNN directory and install the package"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wVOX_chSYdSZ","colab":{}},"source":["import os\n","os.chdir('Mask_RCNN')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QhqpV4bXY1dp","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q6HXBYhDY-Jn","colab":{}},"source":["!python3 setup.py install;"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"isg3ROVwNU10"},"source":["## Load Modules"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KQuRm7a5ZCt2","colab":{}},"source":["import mrcnn\n","import mrcnn.model as modellib\n","from mrcnn.config import Config\n","from mrcnn import utils\n","from mrcnn.model import MaskRCNN\n","\n","import numpy as np\n","import colorsys\n","import argparse\n","import random\n","import os\n","import sys\n","import time\n","import json\n","import skimage\n","import datetime\n","from keras.models import load_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NZT1tDtuNZPp"},"source":["## Link Google Drive and set up directories"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bx82nST2ZQ8r","scrolled":true,"colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sgSrZ5BMa-CP","colab":{}},"source":["homedir='/content/drive/My Drive/Colab Notebooks'\n","datadir=homedir+'/RCNN_test/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XDgXYJTJc8kD","colab":{}},"source":["#files need to be accessed using os !ls does not work.\n","os.listdir(homedir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q_-yptDFNjOK"},"source":["## Define the Config and Dataset classes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0bHXhRkcdM5H","colab":{}},"source":["class myMaskRCNNConfig(Config):\n","    NAME = \"MaskRCNN_config\"\n"," \n","    # set the number of GPUs to use along with the number of images\n","    # per GPU\n","    # Colabs provides a 12GB GPU which should fit 2 images\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 2\n"," \n","    # number of classes (we would normally add +1 for the background)\n","    # tree + BG\n","    NUM_CLASSES = 1+1\n","   \n","    # Number of training steps per epoch (set to number of training samples)\n","    STEPS_PER_EPOCH = 80\n","    \n","    # Learning rate (reduce to stop NaN losses)\n","    LEARNING_RATE=0.001\n","    \n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9\n","    \n","    # setting Max ground truth instances\n","    MAX_GT_INSTANCES=10\n","    \n","config = myMaskRCNNConfig()\n","config.display()\n","\n","check=[]\n","class TreeDataset(utils.Dataset):\n","\n","    def load_dataset(self, dataset_dir):\n","        \"\"\"\n","        Load the images and annotations from Google Drive\n","        The mask coordinates are save in 'polygons'\n","        \"\"\"\n","\n","        self.add_class(\"tree\", 1, \"tree\")\n","\n","        # Load annotations\n","        # VGG Image Annotator saves each image in the form:\n","        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n","        #   'regions': {\n","        #       '0': {\n","        #           'region_attributes': {},\n","        #           'shape_attributes': {\n","        #               'all_points_x': [...],\n","        #               'all_points_y': [...],\n","        #               'name': 'polygon'}},\n","        #       ... more regions ...\n","        #   },\n","        #   'size': 100202\n","        # }\n","        # We mostly care about the x and y coordinates of each region\n","        annotations = json.load(open(os.path.join(homedir, \"treeData.json\")))\n","        annotations = list(annotations.values())  # don't need the dict keys\n","\n","        # The VIA tool saves images in the JSON even if they don't have any\n","        # annotations. Skip unannotated images.\n","        annotations = [a for a in annotations if a['regions']]\n","        for a in annotations:\n","            if a['filename'] in os.listdir(dataset_dir):\n","                # Get the x, y coordinates of points of the polygons that make up\n","                # the outline of each object instance. These are stored in the\n","                # shape_attributes (see json format above)\n","        \n","                if type(a['regions']) is dict:\n","                        polygons = [r['shape_attributes'] for r in a['regions'].values()]\n","                else:\n","                        polygons = [r['shape_attributes'] for r in a['regions']]\n","        \n","                # load_mask() needs the image size to convert polygons to masks.\n","                # Unfortunately, VIA doesn't include it in JSON, so we must read\n","                # the image. This is only managable since the dataset is tiny.\n","                image_path = os.path.join(dataset_dir, a['filename'])\n","                image = skimage.io.imread(image_path)\n","                height, width = image.shape[:2]\n","    \n","                self.add_image(\n","                    \"tree\",\n","                    image_id=a['filename'],\n","                    path=image_path,\n","                    width=width, height=height,\n","                    polygons=polygons)\n","\n","    def load_mask(self, image_id):\n","        \"\"\"\n","        Generate instance masks for an image.\n","        \n","        Returns:\n","        \n","        masks: A bool array of shape [height, width, instance count] with\n","               one mask per instance.\n","        \n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \n","        \"\"\"\n","        # If not a tree dataset image, delegate to background class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"tree\":\n","            print('not a tree!')\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape\n","        info = self.image_info[image_id]\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n","                        dtype=np.uint8)\n","\n","        class_id=[]\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","            mask[rr, cc, i] = 1\n","            class_id.append(self.class_names.index('tree'))\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"tree\":\n","            return info[\"path\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2mFIBpX7Nusc"},"source":["# Prepare the Training and Test Sets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zh84_nepd1XG","colab":{}},"source":["# prepare train set\n","train_set = TreeDataset()\n","train_set.load_dataset(datadir+'/train')\n","train_set.prepare()\n","print('Train: %d' % len(train_set.image_ids))\n","# prepare test/val set\n","test_set = TreeDataset()\n","test_set.load_dataset(datadir+'/test')\n","test_set.prepare()\n","print('Test: %d' % len(test_set.image_ids))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aomxEhkBVLWT"},"source":["# Prepare the Training Model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2tgqfZMZd5t1","colab":{}},"source":["print(\"Loading Mask R-CNN model...\")\n","model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='./')\n","\n","#load the weights for COCO\n","model.load_weights(homedir+'/mask_rcnn_coco.h5', \n","                   by_name=True, \n","                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YZgxO4HnVRlg"},"source":["## Train the Model:\n","If you begin to encounter NaNs in your loss values, try lowering the learning rate by 4 or so times. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NW59utIre5zI","colab":{}},"source":["# train heads with higher lr to speedup the learning\n","\n","model.train(train_set, test_set, learning_rate=2*config.LEARNING_RATE, epochs=15, layers='heads')\n","history = model.keras_model.history.history"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8xCkw9QaN1co"},"source":["## Check the Output\n","Find the output directory name.  \n","In this example it is: 'maskrcnn_config20200218T1359'"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ylWm5b7NeZIn","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GrlzT08QKbu_","colab":{}},"source":["#Move to the latest model directory\n","os.chdir('./maskrcnn_config20200424T1244')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dTIhonZZVtIU"},"source":["## Save Model Weights and History in Google Drive:\n","Find the name of the latest model weights to save"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"knRZdxe1kRzQ","colab":{}},"source":["!ls -lhrt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sfI0JFoqgDFO","colab":{}},"source":["now_str='20200424T1244'\n","\n","try:\n","  os.makedirs(homedir+'saved')\n","except:\n","  print('Save directory exists!')\n","\n","weights_fname =homedir+'saved/weights_tree_'+now_str+'.h5'\n","history_fname =homedir+'saved/history_tree_'+now_str+'.json'\n","\n","model.keras_model.save_weights(weights_fname)\n","\n","with open(history_fname,\"w\") as f:\n","   f.write(json.dumps(str(history)))\n","   "],"execution_count":0,"outputs":[]}]}